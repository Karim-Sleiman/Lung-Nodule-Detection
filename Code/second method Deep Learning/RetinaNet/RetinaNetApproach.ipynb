{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7_NWb5kZEC-M","outputId":"70f34ba9-dc23-44da-e8d2-5c9a91e0ddfd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting SimpleITK\n","  Downloading SimpleITK-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: SimpleITK\n","Successfully installed SimpleITK-2.3.1\n"]}],"source":["pip install SimpleITK"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import SimpleITK as sitk\n","from glob import glob\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","import cv2\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","# Define paths and load the dataset\n","file_path_0 = \"/content/drive/MyDrive/Image Processing/LUNA/subsets/subset0\"\n","file_path_1 = \"/content/drive/MyDrive/Image Processing/LUNA/subset1/subset1\"\n","annotations_path = \"/content/drive/MyDrive/Image Processing/LUNA/annotations.csv\"\n","\n","# Getting list of image files from both subsets\n","file_list_0 = glob(file_path_0 + \"/*.mhd\")\n","file_list_1 = glob(file_path_1 + \"/*.mhd\")\n","\n","# Combine file lists and remove duplicates\n","file_list = list(set(file_list_0 + file_list_1))\n","\n","# Function to make rectangular mask\n","def make_rectangular_mask(center, diam, z, width, height, spacing, origin):\n","    mask = np.zeros([height, width], dtype=np.uint8)\n","    v_center = (center - origin) / spacing\n","    v_xmin = int(v_center[0] - diam / spacing[0] / 2)\n","    v_xmax = int(v_center[0] + diam / spacing[0] / 2)\n","    v_ymin = int(v_center[1] - diam / spacing[1] / 2)\n","    v_ymax = int(v_center[1] + diam / spacing[1] / 2)\n","\n","    # Ensure the coordinates are within the image boundaries\n","    v_xmin = max(v_xmin, 0)\n","    v_xmax = min(v_xmax, width - 1)\n","    v_ymin = max(v_ymin, 0)\n","    v_ymax = min(v_ymax, height - 1)\n","\n","    mask[v_ymin:v_ymax, v_xmin:v_xmax] = 1\n","\n","    return mask\n","\n","# Function to get filename\n","def get_filename(file_list, case):\n","    for f in file_list:\n","        if case in f:\n","            return f\n","\n","# Load annotations\n","df_node = pd.read_csv(annotations_path)\n","df_node[\"file\"] = df_node[\"seriesuid\"].map(lambda file_name: get_filename(file_list, file_name))\n","df_node = df_node.dropna()\n","\n","# Define DataFrame columns\n","columns = [\"seriesuid\", \"sliceindex\", \"imagedata\", \"maskdata\", \"class\"]\n","data = []\n","\n","# Define target size for downsampling\n","target_size = (256, 256)\n","\n","for img_file in tqdm(file_list):\n","    mini_df = df_node[df_node[\"file\"] == img_file]\n","    if mini_df.shape[0] > 0:\n","        itk_img = sitk.ReadImage(img_file)\n","        img_array = sitk.GetArrayFromImage(itk_img)\n","        num_z, height, width = img_array.shape\n","        origin = np.array(itk_img.GetOrigin())\n","        spacing = np.array(itk_img.GetSpacing())\n","\n","        for _, row in mini_df.iterrows():\n","            node_x, node_y, node_z = row[\"coordX\"], row[\"coordY\"], row[\"coordZ\"]\n","            diam = row[\"diameter_mm\"]\n","            center = np.array([node_x, node_y, node_z])\n","            v_center = np.rint((center - origin) / spacing)\n","            i_z = int(v_center[2])\n","\n","            masks = np.zeros((num_z, height, width), dtype=np.uint8)\n","            mask = make_rectangular_mask(center, diam, i_z * spacing[2] + origin[2], width, height, spacing, origin)\n","            masks[i_z] = mask\n","\n","            classes = np.zeros(num_z, dtype=np.uint8)\n","            classes[i_z] = 1\n","\n","            for idx in range(num_z):\n","                # Downsample image and mask\n","                img_resized = cv2.resize(img_array[idx], target_size, interpolation=cv2.INTER_AREA)\n","                mask_resized = cv2.resize(masks[idx], target_size, interpolation=cv2.INTER_NEAREST)\n","                data.append([row[\"seriesuid\"], idx, img_resized, mask_resized, classes[idx]])\n","\n","df_slices = pd.DataFrame(data, columns=columns)\n","df_slices.drop_duplicates(subset=['seriesuid', 'sliceindex', 'class'], inplace=True)\n","df_slices.sort_values(by='class', ascending=False, inplace=True)\n","df_slices.drop_duplicates(subset=['seriesuid', 'sliceindex'], inplace=True)\n","\n","# Split the data into training and validation sets\n","train_df, val_df = train_test_split(df_slices, test_size=0.2, stratify=df_slices['class'], random_state=42)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JkV-pGuzEGsY","outputId":"435dd375-8323-4bfb-db63-74c8cc6e933b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 89/89 [06:08<00:00,  4.14s/it]\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision.models.detection.retinanet import retinanet_resnet50_fpn_v2, RetinaNet_ResNet50_FPN_V2_Weights\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from torch.cuda.amp import autocast, GradScaler\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from glob import glob\n","import SimpleITK as sitk\n","\n","# Focal Loss Definition\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.logits = logits\n","        self.reduce = reduce\n","\n","    def forward(self, inputs, targets):\n","        if self.logits:\n","            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n","        else:\n","            BCE_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n","        pt = torch.exp(-BCE_loss)\n","        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n","\n","        if self.reduce:\n","            return torch.mean(F_loss)\n","        else:\n","            return F_loss\n","\n","# Function to calculate Intersection over Union (IoU)\n","def calculate_iou(box1, box2):\n","    xA = max(box1[0], box2[0])\n","    yA = max(box1[1], box2[1])\n","    xB = min(box1[2], box2[2])\n","    yB = min(box1[3], box2[3])\n","    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n","    box1Area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n","    box2Area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n","    iou = interArea / float(box1Area + box2Area - interArea)\n","    return iou\n","\n","# Function to calculate mean Average Precision (mAP)\n","def calculate_map(pred_boxes, true_boxes, iou_threshold=0.5):\n","    true_positives = []\n","    false_positives = []\n","    scores = []\n","    num_gt_boxes = len(true_boxes)\n","\n","    for pred_box in pred_boxes:\n","        scores.append(pred_box[4])\n","        pred_box = pred_box[:4]\n","\n","        if len(true_boxes) == 0:\n","            false_positives.append(1)\n","            true_positives.append(0)\n","            continue\n","\n","        ious = np.array([calculate_iou(pred_box, gt_box) for gt_box in true_boxes])\n","        max_iou_idx = np.argmax(ious)\n","        max_iou = ious[max_iou_idx]\n","\n","        if max_iou >= iou_threshold:\n","            true_positives.append(1)\n","            false_positives.append(0)\n","            true_boxes.pop(max_iou_idx)\n","        else:\n","            true_positives.append(0)\n","            false_positives.append(1)\n","\n","    cum_true_positives = np.cumsum(true_positives)\n","    cum_false_positives = np.cumsum(false_positives)\n","\n","    precision = cum_true_positives / (cum_true_positives + cum_false_positives)\n","    recall = cum_true_positives / num_gt_boxes\n","\n","    return np.mean(precision), np.mean(recall)\n","\n","def calculate_metrics(model, val_loader):\n","    model.eval()  # Set the model to evaluation mode\n","    iou_scores = []\n","    map_scores = []\n","\n","    with torch.no_grad():  # No gradient calculation\n","        for x_val, y_val in val_loader:\n","            x_val = x_val.to(device)\n","            y_val = [{k: v.to(device) for k, v in t.items()} for t in y_val]\n","\n","            outputs = model(x_val)\n","\n","            for output, target in zip(outputs, y_val):\n","                pred_boxes = output['boxes'].cpu().numpy()\n","                pred_scores = output['scores'].cpu().numpy()\n","                true_boxes = target['boxes'].cpu().numpy()\n","\n","                pred_boxes_with_scores = [np.append(pred_box, score) for pred_box, score in zip(pred_boxes, pred_scores)]\n","\n","                # Calculate IoU\n","                iou = np.mean([calculate_iou(pred_box, true_box) for pred_box, true_box in zip(pred_boxes, true_boxes)])\n","                iou_scores.append(iou)\n","\n","                # Calculate mAP\n","                map_score, recall = calculate_map(pred_boxes_with_scores, true_boxes.tolist())\n","                map_scores.append(map_score)\n","\n","    val_iou = np.mean(iou_scores)\n","    val_map = np.mean(map_scores)\n","\n","    return val_iou, val_map\n"],"metadata":{"id":"5LiHzjEWFMtV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(model, train_loader, val_loader, optimizer, epochs=20):\n","    criterion_cls = FocalLoss(logits=True)  # Use focal loss for classification\n","    criterion_reg = nn.MSELoss()  # Keep MSELoss for regression\n","    scaler = GradScaler()  # Initialize the gradient scaler for mixed precision\n","\n","    train_losses = []\n","    val_iou_scores = []\n","    val_map_scores = []\n","    val_accuracy_scores = []\n","\n","    for epoch in range(epochs):\n","        model.train()  # Set model to training mode.\n","        running_loss = 0.0  # Initialize the running loss.\n","        correct_classifications = 0\n","        total_samples = 0\n","\n","        for x_train, y_train in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n","            optimizer.zero_grad()  # Zero the gradients at the start of a new batch.\n","            x_train = x_train.to(device)\n","            y_train = [{k: v.to(device) for k, v in t.items()} for t in y_train]\n","\n","            with autocast():\n","                outputs = model(x_train)\n","                loss_dict = model(x_train, y_train)\n","                losses = sum(loss for loss in loss_dict.values())\n","\n","            scaler.scale(losses).backward()  # Backpropagation with mixed precision\n","            scaler.step(optimizer)  # Update weights with scaled gradients\n","            scaler.update()  # Update the scale for the next iteration\n","            running_loss += losses.item()  # Accumulate the loss\n","\n","        train_losses.append(running_loss / len(train_loader))\n","\n","        # Calculate validation metrics\n","        val_iou, val_map = calculate_metrics(model, val_loader)\n","        val_iou_scores.append(val_iou)\n","        val_map_scores.append(val_map)\n","\n","        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Val IOU: {val_iou:.4f}, Val mAP: {val_map:.4f}\")\n","\n","    # Plotting loss and metrics\n","    epochs_range = range(1, epochs + 1)\n","    plt.figure(figsize=(12, 6))\n","\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs_range, train_losses, label='Training Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.title('Training Loss Over Epochs')\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs_range, val_iou_scores, label='Validation IOU')\n","    plt.plot(epochs_range, val_map_scores, label='Validation mAP')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Score')\n","    plt.title('Validation Metrics Over Epochs')\n","    plt.legend()\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Initialize and train the model\n","train_dataset = CustomDataset(train_df)\n","val_dataset = CustomDataset(val_df)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2, pin_memory=True)\n","\n","model = retinanet_resnet50_fpn_v2(weights=RetinaNet_ResNet50_FPN_V2_Weights.DEFAULT)\n","model = model.to(device)\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.00001, momentum=0.9)\n","train_model(model, train_loader, val_loader, optimizer, epochs=20)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vCtpOAu0FiqT","outputId":"f49f3662-8310-4c43-a03e-1f0d07d7fdd0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=RetinaNet_ResNet50_FPN_V2_Weights.COCO_V1`. You can also use `weights=RetinaNet_ResNet50_FPN_V2_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/retinanet_resnet50_fpn_v2_coco-5905b1c5.pth\" to /root/.cache/torch/hub/checkpoints/retinanet_resnet50_fpn_v2_coco-5905b1c5.pth\n","100%|██████████| 146M/146M [00:02<00:00, 64.4MB/s]\n","/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n","  warnings.warn(\n","Epoch 1/20:   0%|          | 0/921 [00:00<?, ?it/s]"]}]},{"cell_type":"markdown","source":["##TESTING!!"],"metadata":{"id":"LLcIlUzPHOFQ"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","from torch.utils.data import DataLoader, Dataset\n","\n","\n","# Define a dataset class for the test data\n","class TestDataset(Dataset):\n","    def __init__(self, file_list):\n","        self.file_list = file_list\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, idx):\n","        file_path = self.file_list[idx]\n","        itk_img = sitk.ReadImage(file_path)\n","        img_array = sitk.GetArrayFromImage(itk_img)\n","        img_array = (img_array - img_array.min()) / (img_array.max() - img_array.min())\n","        img_tensor = torch.tensor(img_array, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n","        return img_tensor, file_path\n","\n","# Load the test data\n","subset9_path = \"/content/drive/MyDrive/Image Processing/LUNA/subsets/subset0\"\n","file_list = glob(subset9_path + \"/*.mhd\")\n","\n","test_dataset = TestDataset(file_list)\n","test_loader = DataLoader(test_dataset, batch_size=5, shuffle=False)  # Adjust the batch size as needed\n","\n","# Function to visualize the results\n","def visualize_detections(images, file_paths, boxes, scores, threshold=0.5):\n","    batch_size = len(images)\n","    fig, axes = plt.subplots(batch_size, 2, figsize=(15, 5 * batch_size))\n","\n","    for i in range(batch_size):\n","        image = images[i][0].cpu().numpy()\n","        file_path = file_paths[i]\n","        box = boxes[i]\n","        score = scores[i]\n","\n","        # Normalize the image for visualization\n","        image = (image - image.min()) / (image.max() - image.min())\n","\n","        axes[i, 0].imshow(image, cmap='gray')\n","        axes[i, 0].set_title(f'Image: {file_path}')\n","        axes[i, 0].axis('off')\n","\n","        axes[i, 1].imshow(image, cmap='gray')\n","        has_nodule = False\n","        for b, s in zip(box, score):\n","            if s > threshold:\n","                has_nodule = True\n","                x1, y1, x2, y2 = b\n","                color = 'red' if s > 0.8 else 'blue'\n","                rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor=color, linewidth=2)\n","                axes[i, 1].add_patch(rect)\n","                axes[i, 1].text(x1, y1, f'{s:.2f}', bbox=dict(facecolor='yellow', alpha=0.5))\n","        if not has_nodule:\n","            axes[i, 1].set_title('No Nodule Detected', color='green')\n","        else:\n","            axes[i, 1].set_title('Detections')\n","        axes[i, 1].axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Function to run the model on the test data and visualize the results\n","def test_model(model, test_loader, device, threshold=0.5):\n","    model.eval()\n","    with torch.no_grad():\n","        for images, file_paths in tqdm(test_loader, desc=\"Testing\"):\n","            images = images.to(device)\n","            outputs = model(images)\n","\n","            # Get the predicted boxes and scores\n","            boxes = [output['boxes'].cpu().numpy() for output in outputs]\n","            scores = [output['scores'].cpu().numpy() for output in outputs]\n","\n","            # Visualize the detections\n","            visualize_detections(images.cpu(), file_paths, boxes, scores, threshold)\n","\n","# Use the trained model from the current session\n","model = model.to(device)  # Ensure the model is on the correct device\n","\n","# Run the test and visualize results\n","test_model(model, test_loader, device)\n"],"metadata":{"id":"CPQFvFhGHIVU"},"execution_count":null,"outputs":[]}]}