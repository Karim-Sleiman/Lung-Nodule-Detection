{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOvWBZwumqYSdZxDyatxLo/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Retinanet with Resnet50 Backbone"],"metadata":{"id":"4l9fU8FDBW_x"}},{"cell_type":"code","source":["!pip install SimpleITK pandas numpy torch torchvision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GeQfR3FqmSuN","executionInfo":{"status":"ok","timestamp":1717092146783,"user_tz":-120,"elapsed":13663,"user":{"displayName":"Karim Sleiman","userId":"10366541738177439067"}},"outputId":"b0b2d197-3750-4e95-9fb7-883bcf9ba9e3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: SimpleITK in /usr/local/lib/python3.10/dist-packages (2.3.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RtOIwxeIEWbu","executionInfo":{"status":"ok","timestamp":1717092184428,"user_tz":-120,"elapsed":1935,"user":{"displayName":"Karim Sleiman","userId":"10366541738177439067"}},"outputId":"48abd319-e12a-4fcf-eb6d-0e2f6f2530be"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content')\n","\n","import SimpleITK as sitk\n","import numpy as np\n","import pandas as pd\n","import os\n","from glob import glob\n","import torch\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import torch.nn as nn\n","from torch.optim import SGD\n","from torchvision.models.detection import RetinaNet, retinanet_resnet50_fpn\n","from torchvision.models.detection.backbone_utils import resnet_fpn_backbone, _resnet_fpn_extractor\n","from torchvision.models import resnet50, ResNet50_Weights\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","import torchvision.transforms as T\n","from sklearn.metrics import average_precision_score"],"metadata":{"id":"fYCeG422HG0n","executionInfo":{"status":"ok","timestamp":1717092197867,"user_tz":-120,"elapsed":12209,"user":{"displayName":"Karim Sleiman","userId":"10366541738177439067"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class NoduleDataset(Dataset):\n","    def __init__(self, file_path, annotations_sub0_path, transform=None):\n","        self.file_list = glob(os.path.join(file_path, \"*.mhd\"))\n","        self.annotations = pd.read_csv(annotations_sub0_path)\n","        self.transform = transform\n","        self.slices = []\n","        self.slice_annotations = []\n","\n","        # Load and process the images\n","        for img_file in self.file_list:\n","            print(f\"Processing file: {img_file}\")\n","            itk_img = sitk.ReadImage(img_file)\n","            img_array = sitk.GetArrayFromImage(itk_img)\n","\n","            # Clip values lower than -1024\n","            img_array = np.clip(img_array, -1024, None)\n","            # Normalize to 0-1 range\n","            img_array = (img_array - np.min(img_array)) / (np.max(img_array) - np.min(img_array))\n","\n","            series_uid = os.path.basename(img_file).split('.mhd')[0]\n","            # print(f\"Extracted series UID: {series_uid}\")\n","            series_annotations = self.annotations[self.annotations['seriesuid'] == series_uid]\n","            # print(f\"Annotations found: {len(series_annotations)} for series UID: {series_uid}\")\n","\n","            for i in range(img_array.shape[0]):\n","                slice_annots = self.get_slice_annotations(series_annotations, i)\n","                if slice_annots['boxes'].size(0) > 0:  # Only add slices with annotations\n","                    self.slices.append(img_array[i])\n","                    self.slice_annotations.append(slice_annots)\n","\n","    def __len__(self):\n","        return len(self.slices)\n","\n","    def __getitem__(self, idx):\n","        slice = self.slices[idx]\n","        slice = torch.tensor(slice, dtype=torch.float32).unsqueeze(0)  # Add channel dimension (1, H, W)\n","\n","        if self.transform:\n","            slice = self.transform(slice)\n","\n","        target = self.slice_annotations[idx]\n","        return slice, target\n","\n","    def get_slice_annotations(self, series_annotations, slice_idx):\n","        bboxes = []\n","        labels = []\n","        for _, row in series_annotations.iterrows():\n","            z, y, x = map(float, row['cartesian_coords(zyx)'].strip('()').split(', '))\n","            diameter = float(row['diameter_mm'])\n","            if int(z) == slice_idx:\n","                bbox = self.get_bbox_from_cartesian(x, y, diameter)\n","                bboxes.append(bbox)\n","                labels.append(1)  # Assuming label 1 for nodules\n","\n","        if bboxes:\n","            bboxes = torch.tensor(bboxes, dtype=torch.float32)\n","            labels = torch.tensor(labels, dtype=torch.int64)\n","            # print(f\"Annotations found for Slice IDX: {slice_idx}: {len(bboxes)}\")\n","        else:\n","            bboxes = torch.zeros((0, 4), dtype=torch.float32)\n","            labels = torch.zeros((0,), dtype=torch.int64)\n","\n","        return {'boxes': bboxes, 'labels': labels}\n","\n","    def get_bbox_from_cartesian(self, x, y, diameter):\n","        # Convert Cartesian coordinates to bounding box\n","        bbox = [x - diameter / 2, y - diameter / 2, x + diameter / 2, y + diameter / 2]  # xmin, ymin, xmax, ymax\n","        return bbox\n","\n","def collate_fn(batch):\n","    slices = [item[0] for item in batch]\n","    targets = [item[1] for item in batch]\n","\n","    slices = torch.stack(slices, dim=0)\n","\n","    return slices, targets\n","\n","# Example usage\n","file_path = '/content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0'\n","annotations_sub0_path = '/content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subset0_annotations_expanded.csv'\n","\n","# Define transformation (if needed)\n","transform = None\n","\n","dataset = NoduleDataset(file_path, annotations_sub0_path, transform=transform)\n","dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=0, collate_fn=collate_fn)\n","'''\n","# Testing the DataLoader with debug information\n","for batch_idx, (data, targets) in enumerate(dataloader):\n","    non_empty_annotations = [i for i in range(len(data)) if targets[i]['boxes'].size(0) > 0]\n","    if non_empty_annotations:\n","        print(f\"Batch {batch_idx + 1}\")\n","        print(f\"Data: {data.shape}\")\n","        print(f\"Targets: {targets}\")\n","        for idx in non_empty_annotations:\n","            print(f\"Data sample {idx + 1}:\")\n","            print(f\"Boxes: {targets[idx]['boxes']}\")\n","            print(f\"Labels: {targets[idx]['labels']}\")\n","        break  # Print only the first batch with annotations for brevity\n","'''"],"metadata":{"id":"KU4FVyrNHDnD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"91d3eb73-6f1f-4451-dcb3-8a0d668b4066"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.105756658031515062000744821260.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.108197895896446896160048741492.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.109002525524522225658609808059.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.111172165674661221381920536987.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.122763913896761494371822656720.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.124154461048929153767743874565.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.126121460017257137098781143514.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.126264578931778258890371755354.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.128023902651233986592378348912.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.129055977637338639741695800950.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.130438550890816550994739120843.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.134996872583497382954024478441.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.137763212752154081977261297097.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.138080888843357047811238713686.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.139258777898746693365877042411.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.139713436241461669335487719526.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.141069661700670042960678408762.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.144438612068946916340281098509.mhd\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.146429221666426688999739595820.mhd\n"]}]},{"cell_type":"markdown","source":["## Define the Model (ResNet50 Backbone Retinanet)\n","\n"],"metadata":{"id":"16_ulySw4XP6"}},{"cell_type":"code","source":["class CustomRetinaNet(nn.Module):\n","    def __init__(self, num_classes):\n","        super(CustomRetinaNet, self).__init__()\n","        # Load a pretrained ResNet-50 model with the updated weights parameter\n","        backbone = resnet50(weights=ResNet50_Weights.DEFAULT)\n","        self.backbone = _resnet_fpn_extractor(backbone, trainable_layers=5)\n","\n","        # Create the RetinaNet model with the custom backbone\n","        self.model = RetinaNet(self.backbone, num_classes=num_classes)\n","\n","    def forward(self, images, targets=None):\n","        return self.model(images, targets)\n","\n","def create_model(num_classes):\n","    model = CustomRetinaNet(num_classes)\n","    return model\n","\n","# Global parameters\n","NUM_CLASSES = 2  # 1 class (nodule) + background\n","BATCH_SIZE = 4\n","LEARNING_RATE = 0.001  # Initial learning rate for SGD\n","MOMENTUM = 0.9  # Momentum for SGD\n","WEIGHT_DECAY = 0.0001  # Weight decay for regularization\n","NUM_EPOCHS = 10\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Create the model\n","model = create_model(NUM_CLASSES).to(DEVICE)"],"metadata":{"id":"S8EvpMblSDEU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Define the map metric"],"metadata":{"id":"sFg0P1JTUoJL"}},{"cell_type":"code","source":["# Evaluate predictions\n","def evaluate_predictions(pred_boxes, pred_scores, true_boxes, true_labels, iou_threshold=0.5):\n","    all_ap = []\n","    for i in range(len(true_boxes)):\n","        pred_box = pred_boxes[i]\n","        pred_score = pred_scores[i]\n","        true_box = true_boxes[i]\n","        true_label = true_labels[i]\n","\n","        if len(pred_box) == 0:\n","            continue\n","\n","        if len(true_box) == 0:\n","            continue\n","\n","        iou = calculate_iou(pred_box, true_box)\n","\n","        matches = iou > iou_threshold\n","        tp = np.sum(matches)\n","        fp = len(pred_box) - tp\n","        fn = len(true_box) - tp\n","\n","        precision = tp / (tp + fp)\n","        recall = tp / (tp + fn)\n","\n","        ap = average_precision_score(matches, pred_score[:len(matches)])\n","        all_ap.append(ap)\n","\n","    mean_ap = np.mean(all_ap) if all_ap else 0.0\n","    return mean_ap, all_ap\n","\n","def calculate_iou(boxes1, boxes2):\n","    # Calculate intersection over union\n","    x1 = np.maximum(boxes1[:, 0], boxes2[:, 0])\n","    y1 = np.maximum(boxes1[:, 1], boxes2[:, 1])\n","    x2 = np.minimum(boxes1[:, 2], boxes2[:, 2])\n","    y2 = np.minimum(boxes1[:, 3], boxes2[:, 3])\n","\n","    intersection = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)\n","    area1 = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])\n","    area2 = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])\n","    union = area1 + area2 - intersection\n","\n","    iou = intersection / union\n","    return iou"],"metadata":{"id":"HhMzGc4fUvD-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Define Training loop"],"metadata":{"id":"Je5VbgVG5tpa"}},{"cell_type":"code","source":["# Optimizer and learning rate scheduler\n","optimizer = SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n","\n","# Function to train the model\n","def train_model(model, train_loader, val_loader, optimizer, lr_scheduler, num_epochs):\n","    model.train()\n","    for epoch in range(num_epochs):\n","        epoch_loss = 0\n","        for batch_idx, (images, targets) in enumerate(train_loader):\n","            images = list(image.to(DEVICE) for image in images)\n","            targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n","\n","            optimizer.zero_grad()\n","            loss_dict = model(images, targets)\n","            losses = sum(loss for loss in loss_dict.values())\n","            losses.backward()\n","            optimizer.step()\n","\n","            epoch_loss += losses.item()\n","\n","            if batch_idx % 10 == 0:\n","                print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{batch_idx}/{len(train_loader)}], Loss: {losses.item():.4f}\")\n","\n","        lr_scheduler.step()\n","        print(f\"Epoch [{epoch + 1}/{num_epochs}] completed with average loss: {epoch_loss / len(train_loader):.4f}\")\n","\n","        # Validate the model\n","        model.eval()\n","        with torch.no_grad():\n","            val_loss = 0\n","            all_pred_boxes = []\n","            all_pred_scores = []\n","            all_true_boxes = []\n","            all_true_labels = []\n","\n","            for images, targets in val_loader:\n","                images = list(image.to(DEVICE) for image in images)\n","                targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n","\n","                outputs = model(images)\n","\n","                for i in range(len(outputs)):\n","                    all_pred_boxes.append(outputs[i]['boxes'].cpu().numpy())\n","                    all_pred_scores.append(outputs[i]['scores'].cpu().numpy())\n","                    all_true_boxes.append(targets[i]['boxes'].cpu().numpy())\n","                    all_true_labels.append(targets[i]['labels'].cpu().numpy())\n","\n","            mean_ap, aps = evaluate_predictions(all_pred_boxes, all_pred_scores, all_true_boxes, all_true_labels)\n","            print(f\"Validation mAP: {mean_ap}, APs: {aps}\")\n","\n","        model.train()  # Switch back to training mode\n","\n","        # Save checkpoint\n","        checkpoint_path = f\"retinanet_epoch_{epoch + 1}.pth\"\n","        torch.save(model.state_dict(), checkpoint_path)\n","        print(f\"Model checkpoint saved at {checkpoint_path}\")\n","\n","# Create dataset and split into training and validation sets\n","dataset = NoduleDataset(file_path, annotations_sub0_path, transform=transform)\n","train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, collate_fn=collate_fn)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, collate_fn=collate_fn)\n","\n","# Start training\n","train_model(model, train_loader, val_loader, optimizer, lr_scheduler, NUM_EPOCHS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nmq6S3zv5tL9","executionInfo":{"status":"ok","timestamp":1717087526834,"user_tz":-120,"elapsed":38343,"user":{"displayName":"Karim Sleiman","userId":"10366541738177439067"}},"outputId":"9369f72d-14b9-4429-cc92-07650a1b9418"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0_test/1.3.6.1.4.1.14519.5.2.1.6279.6001.979083010707182900091062408058.mhd\n","Extracted series UID: 1.3.6.1.4.1.14519.5.2.1.6279.6001.979083010707182900091062408058\n","Annotations found: 1 for series UID: 1.3.6.1.4.1.14519.5.2.1.6279.6001.979083010707182900091062408058\n","Annotations found for Slice IDX: 56: 1\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0_test/1.3.6.1.4.1.14519.5.2.1.6279.6001.898642529028521482602829374444.mhd\n","Extracted series UID: 1.3.6.1.4.1.14519.5.2.1.6279.6001.898642529028521482602829374444\n","Annotations found: 2 for series UID: 1.3.6.1.4.1.14519.5.2.1.6279.6001.898642529028521482602829374444\n","Annotations found for Slice IDX: 66: 1\n","Annotations found for Slice IDX: 97: 1\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0_test/1.3.6.1.4.1.14519.5.2.1.6279.6001.832260670372728970918746541371.mhd\n","Extracted series UID: 1.3.6.1.4.1.14519.5.2.1.6279.6001.832260670372728970918746541371\n","Annotations found: 2 for series UID: 1.3.6.1.4.1.14519.5.2.1.6279.6001.832260670372728970918746541371\n","Annotations found for Slice IDX: 57: 1\n","Annotations found for Slice IDX: 111: 1\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0_test/1.3.6.1.4.1.14519.5.2.1.6279.6001.868211851413924881662621747734.mhd\n","Extracted series UID: 1.3.6.1.4.1.14519.5.2.1.6279.6001.868211851413924881662621747734\n","Annotations found: 3 for series UID: 1.3.6.1.4.1.14519.5.2.1.6279.6001.868211851413924881662621747734\n","Annotations found for Slice IDX: 117: 1\n","Annotations found for Slice IDX: 143: 1\n","Annotations found for Slice IDX: 165: 1\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0_test/1.3.6.1.4.1.14519.5.2.1.6279.6001.905371958588660410240398317235.mhd\n","Extracted series UID: 1.3.6.1.4.1.14519.5.2.1.6279.6001.905371958588660410240398317235\n","Annotations found: 1 for series UID: 1.3.6.1.4.1.14519.5.2.1.6279.6001.905371958588660410240398317235\n","Annotations found for Slice IDX: 111: 1\n","Processing file: /content/drive/Shareddrives/IA DL_project/ML IA/LUNA16/subsets/subset0_test/1.3.6.1.4.1.14519.5.2.1.6279.6001.975254950136384517744116790879.mhd\n","Extracted series UID: 1.3.6.1.4.1.14519.5.2.1.6279.6001.975254950136384517744116790879\n","Annotations found: 0 for series UID: 1.3.6.1.4.1.14519.5.2.1.6279.6001.975254950136384517744116790879\n","Epoch [1/10], Step [0/2], Loss: 3.8263\n","Epoch [1/10] completed with average loss: 3.5716\n","Validation mAP: 0.0, APs: []\n","Model checkpoint saved at retinanet_epoch_1.pth\n","Epoch [2/10], Step [0/2], Loss: 3.7708\n","Epoch [2/10] completed with average loss: 3.5566\n","Validation mAP: 0.0, APs: []\n","Model checkpoint saved at retinanet_epoch_2.pth\n","Epoch [3/10], Step [0/2], Loss: 3.5655\n","Epoch [3/10] completed with average loss: 3.5337\n","Validation mAP: 0.0, APs: []\n","Model checkpoint saved at retinanet_epoch_3.pth\n","Epoch [4/10], Step [0/2], Loss: 3.3796\n","Epoch [4/10] completed with average loss: 3.4992\n","Validation mAP: 0.0, APs: []\n","Model checkpoint saved at retinanet_epoch_4.pth\n","Epoch [5/10], Step [0/2], Loss: 3.0539\n","Epoch [5/10] completed with average loss: 3.5428\n","Validation mAP: 0.0, APs: []\n","Model checkpoint saved at retinanet_epoch_5.pth\n","Epoch [6/10], Step [0/2], Loss: 3.4906\n","Epoch [6/10] completed with average loss: 3.4550\n","Validation mAP: 0.0, APs: []\n","Model checkpoint saved at retinanet_epoch_6.pth\n","Epoch [7/10], Step [0/2], Loss: 3.5977\n","Epoch [7/10] completed with average loss: 3.4188\n","Validation mAP: 0.0, APs: []\n","Model checkpoint saved at retinanet_epoch_7.pth\n","Epoch [8/10], Step [0/2], Loss: 3.3132\n","Epoch [8/10] completed with average loss: 3.4695\n","Validation mAP: 0.0, APs: []\n","Model checkpoint saved at retinanet_epoch_8.pth\n","Epoch [9/10], Step [0/2], Loss: 3.3288\n","Epoch [9/10] completed with average loss: 3.4595\n","Validation mAP: 0.0, APs: []\n","Model checkpoint saved at retinanet_epoch_9.pth\n","Epoch [10/10], Step [0/2], Loss: 3.3092\n","Epoch [10/10] completed with average loss: 3.4653\n","Validation mAP: 0.0, APs: []\n","Model checkpoint saved at retinanet_epoch_10.pth\n"]}]}]}